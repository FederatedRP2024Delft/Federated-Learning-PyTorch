{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T22:20:23.316631Z",
     "start_time": "2024-05-02T22:20:23.285671Z"
    }
   },
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from plots import plot_training_result, plot_image_data\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from vae.mnist_vae import VaeAutoencoderClassifier\n",
    "from image_classifier.image_classifier import MNISTClassifier\n",
    "from utils import frechet_inception_distance"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T22:20:23.541290Z",
     "start_time": "2024-05-02T22:20:23.336276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_data = torchvision.datasets.MNIST(root='../data/MNIST_train', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "testing_data = torchvision.datasets.MNIST(root='../data/MNIST_test', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "print(training_data)\n",
    "print(testing_data)\n",
    "\n",
    "input = training_data.data[:60000] / 255.0\n",
    "labels = training_data.targets[:60000]\n",
    "\n",
    "print(input.shape)"
   ],
   "id": "16ee1ea9b79842dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../data/MNIST_train\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ../data/MNIST_test\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-02T22:20:23.541290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train VAE\n",
    "vae = VaeAutoencoderClassifier(dim_encoding=2)\n",
    "\n",
    "merged_dataset = ConcatDataset([training_data, testing_data])\n",
    "\n",
    "# alpha value of 5000 and 20 epochs seems to be the best\n",
    "# increasing alpha will decrease KL divergence loss but worse generated data\n",
    "vae_classifier_model, total_losses, classifier_accuracy_li, classifier_loss_li, vae_loss_li, kl_loss_li = vae.train_model(\n",
    "    merged_dataset,\n",
    "    batch_size=100,\n",
    "    alpha=5000.0,\n",
    "    epochs=20\n",
    ")"
   ],
   "id": "415ddc3205ecd96b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch:  1\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# plot generated data\n",
    "image_tensor, label_tensor = vae.generate_data(n_samples=5)\n",
    "plot_image_data(image_tensor.cpu().detach().numpy(), label_tensor.cpu().detach().numpy())"
   ],
   "id": "b8346adb2f156a85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# move tensors to cpu before converting to np array\n",
    "np_classifier_accuracy_li = []\n",
    "np_classifier_loss_li = []\n",
    "np_vae_loss_li = []\n",
    "np_kl_loss_li = []\n",
    "\n",
    "for output in classifier_accuracy_li:\n",
    "    if isinstance(output, Tensor):\n",
    "        np_classifier_accuracy_li.append(output.cpu().detach().numpy())\n",
    "\n",
    "for output in classifier_loss_li:\n",
    "    if isinstance(output, Tensor):\n",
    "        np_classifier_loss_li.append(output.cpu().detach().numpy())\n",
    "        \n",
    "for output in vae_loss_li:\n",
    "    if isinstance(output, Tensor):\n",
    "        np_vae_loss_li.append(output.cpu().detach().numpy())\n",
    "\n",
    "for output in kl_loss_li:\n",
    "    if isinstance(output, Tensor):\n",
    "        np_kl_loss_li.append(output.cpu().detach().numpy())\n"
   ],
   "id": "ae8696b75203674b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# plot results\n",
    "plot_training_result(\n",
    "    input=input,\n",
    "    labels=labels,\n",
    "    vae_model_classifier=vae_classifier_model,\n",
    "    vae_loss_li=np_vae_loss_li,\n",
    "    total_losses=total_losses, \n",
    "    classifier_accuracy_li=np_classifier_accuracy_li, \n",
    "    classifier_loss_li=np_classifier_loss_li,\n",
    "    kl_loss_li=np_kl_loss_li\n",
    ")"
   ],
   "id": "9ce187083360ae0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier for performance evaluation\n",
    "\n",
    "classifier = MNISTClassifier(input_size=784, num_classes=10)\n",
    "classifier.train_model(training_data, batch_size=100, epochs=5)\n",
    "accuracy = classifier.test_model(testing_data)\n",
    "print(\"Test accuracy: \", accuracy)"
   ],
   "id": "1c22d0587d317480",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = vae.generate_data(n_samples=1)\n",
    "\n",
    "for i in range(100):\n",
    "    image_tensor, label_tensor = vae.generate_data(n_samples=100)\n",
    "    x = torch.cat((x, image_tensor), dim=0)\n",
    "    y = torch.cat((y, label_tensor), dim=0)\n",
    "\n",
    "assert x.shape[0] == y.shape[0]\n",
    "print(\"Number of images: \", x.shape[0])"
   ],
   "id": "1296469b8fed46fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# test quality of images\n",
    "\n",
    "# image classification\n",
    "accuracy = classifier.test_model_syn_img(x, y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# generate 500 images\n",
    "syn_input, _ = vae.generate_data(n_samples=500)\n",
    "input = input[:500]\n",
    "\n",
    "input_rgb = input.view(-1, 1, 28, 28).repeat(1, 3, 1, 1)\n",
    "syn_input_rgb = syn_input.view(-1, 1, 28, 28).repeat(1, 3, 1, 1)\n",
    "\n",
    "# compute FID score (worst: 131, best: 85)\n",
    "# 0 score only possible if absolutely identical\n",
    "fid_score = frechet_inception_distance(input_rgb, syn_input_rgb)\n",
    "print(\"Frechet Inception Distance: \", fid_score)"
   ],
   "id": "6fe82f31416a35a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8facfceca09d32d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
