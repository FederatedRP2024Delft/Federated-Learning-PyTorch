{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T22:06:11.249040Z",
     "start_time": "2024-05-15T22:06:11.245396Z"
    }
   },
   "source": [
    "import torchvision\n",
    "\n",
    "from torch import cuda, device, Tensor\n",
    "from src.plots import plot_vae_training_result, plot_cifar_image\n",
    "from src.vae.cifar_vae import ConditionalVae\n",
    "from src.image_classifier.image_classifier import CIFAR10Classifier\n",
    "\n",
    "device = device('cuda' if cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:06:13.483458Z",
     "start_time": "2024-05-15T22:06:12.367021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "# https://github.com/kuangliu/pytorch-cifar/issues/19\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_data = torchvision.datasets.CIFAR10(root='../data/CIFAR10_train', train=True, download=True, transform=transform)\n",
    "testing_data = torchvision.datasets.CIFAR10(root='../data/CIFAR10_test', train=False, download=True, transform=transform)\n",
    "\n",
    "print(training_data)\n",
    "print(testing_data)\n",
    "\n",
    "input = training_data.data[:50000]\n",
    "labels = training_data.targets[:50000]"
   ],
   "id": "16ee1ea9b79842dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ../data/CIFAR10_train\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ../data/CIFAR10_test\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-15T22:06:20.415952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train VAE\n",
    "vae = ConditionalVae(dim_encoding=100).to(device)\n",
    "\n",
    "vae_model, vae_loss_li, kl_loss_li = vae.train_model(\n",
    "    training_data=training_data,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    beta=30.0,\n",
    "    learning_rate=0.001\n",
    ")"
   ],
   "id": "415ddc3205ecd96b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch:  1\n",
      "Finished epoch:  2\n",
      "Finished epoch:  3\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# move tensors to cpu before converting to np array\n",
    "np_kl_loss_li = []\n",
    "\n",
    "for output in kl_loss_li:\n",
    "    if isinstance(output, Tensor):\n",
    "        np_kl_loss_li.append(output.cpu().detach().numpy())\n",
    "\n",
    "# plot results\n",
    "plot_vae_training_result(\n",
    "    input=input,\n",
    "    labels=labels,\n",
    "    vae_model=vae_model,\n",
    "    vae_loss_li=vae_loss_li,\n",
    "    kl_loss_li=np_kl_loss_li\n",
    ")"
   ],
   "id": "9ce187083360ae0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check output\n",
    "n_samples = 5\n",
    "\n",
    "samples = training_data.data[:n_samples]\n",
    "plot_cifar_image(samples)\n",
    "\n",
    "# airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "# (n_samples, 3, 32, 32)\n",
    "output = vae.generate_data(n_samples=n_samples, target_label=1)\n",
    "\n",
    "# plt.imshow(np.transpose(output[0].cpu().numpy(), (1, 2, 0)), cmap='gray')\n",
    "\n",
    "# vae expects permuted input of (<batch_size, channels, height, width>)\n",
    "output = output.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "\n",
    "assert output.shape == (n_samples, 32, 32, 3)\n",
    "\n",
    "plot_cifar_image(output)"
   ],
   "id": "9120a59d9016136e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# train classifier for performance evaluation\n",
    "classifier = CIFAR10Classifier().to(device)\n",
    "\n",
    "classifier.train_model(training_data, batch_size=32, learning_rate=0.01, epochs=10)\n",
    "accuracy = classifier.test_model(testing_data)\n",
    "print(\"Test accuracy: \", accuracy)"
   ],
   "id": "1c22d0587d317480",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "x = vae.generate_data(n_samples=5, target_label=0)\n",
    "labels = classifier.generate_labels(x.to(device))\n",
    "print(\"Labels: \", labels)"
   ],
   "id": "1296469b8fed46fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:05:45.148332Z",
     "start_time": "2024-05-15T22:05:45.146275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Determine FID\n",
    "# # generate 500 images\n",
    "# syn_input, _ = vae.generate_data(n_samples=500)\n",
    "# input = input[:500]\n",
    "# \n",
    "# input_rgb = input.view(-1, 1, 28, 28).repeat(1, 3, 1, 1)\n",
    "# syn_input_rgb = syn_input.view(-1, 1, 28, 28).repeat(1, 3, 1, 1)\n",
    "# \n",
    "# # compute FID score\n",
    "# fid_score = frechet_inception_distance(input_rgb, syn_input_rgb)\n",
    "# print(\"Frechet Inception Distance: \", fid_score)"
   ],
   "id": "8facfceca09d32d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:05:45.150878Z",
     "start_time": "2024-05-15T22:05:45.149176Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "e096decd0448907b",
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
